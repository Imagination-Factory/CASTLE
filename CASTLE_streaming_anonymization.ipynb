{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>k-Anonymity on Streaming data</h1>\n",
    "\n",
    "In this implementation we incorporate the CASTLE framework (concepts). The idea is to provide an anonymization of a data stream by also ensuring some quality of the anonymized output data stream.\n",
    "\n",
    "_Implementation written by Christian Becker._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Setting up the environment:</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use Pandas to work with the data as it makes working with categorical data very easy\n",
    "import pandas as pd\n",
    "# we use random for choosing random items of a list\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the quasi attributes used in this approach\n",
    "# this is a list of the column names in our dataset (as the file doesn't contain any headers)\n",
    "column_names = (\n",
    "    'one',\n",
    "    'two', \n",
    "    'three', \n",
    "    'four',\n",
    "    'five',\n",
    "    'six',\n",
    ")\n",
    "\n",
    "# if there are categorical attributes:\n",
    "# these fields will require some special treatment\n",
    "categorical = set((\n",
    "  #  'education',\n",
    "))\n",
    "# we load the data example from the txt using panda's library function\n",
    "df = pd.read_csv(\"ExampleListOfMAcadresses.txt\", sep=\":\", header=None, names=column_names, index_col=False, engine='python');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modification of the sample data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the categorical attributes as types as such\n",
    "for name in categorical:\n",
    "    df[name] = df[name].astype('category')\n",
    "   \n",
    "def input_conversion():\n",
    "    #convert hex string values into int values\n",
    "    for name in column_names:\n",
    "        df[name] = df[name].apply(lambda x: int(x, 16))\n",
    "\n",
    "    df.head()\n",
    "    \n",
    "input_conversion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Definition of a cluster</h3>\n",
    "We work with ks-anonymized clusters where we have an n-dimensional space defined by intervals of values by the respective tuples of the tuples of the respective cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with columns same as the input is\n",
    "non_ks_clusters = [] # initially empty , array of DataFrame(columns=column_names_cluster) # stored in memory\n",
    "ks_clusters = [] # already outputted, see above\n",
    "\n",
    "# each attribute is stored as a dictionary which defines an interval\n",
    "attr_range = {\n",
    "  \"min\":  \"NaN\",\n",
    "  \"max\": \"NaN\"\n",
    "}\n",
    "\n",
    "tau_global = 10 # initialize a global var (will be overwrittten in main function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column names for the non-ks-clusters in memory because they also need to contain a list\n",
    "# of the indezes of the tuples in order to know in which cluster a tuple falls or which and\n",
    "# how many tuples have (already) been associated with a cluster\n",
    "column_names_cluster = (\n",
    "    'one',\n",
    "    'two', \n",
    "    'three', \n",
    "    'four',\n",
    "    'five',\n",
    "    'six',\n",
    "    'tuples_IDs',\n",
    "    'clusterID'\n",
    ")\n",
    "\n",
    "#Creation of a non_ks_cluster\n",
    "def create_new_cluster(new_tuple, new_cluster_index):\n",
    "    global non_ks_clusters\n",
    "    global number_of_cluster_indezes\n",
    "    \n",
    "    # create new cluster\n",
    "    new_non_ks_cluster = pd.DataFrame(columns=column_names_cluster)\n",
    "    for i_c, column in enumerate(new_non_ks_cluster):\n",
    "        if column != 'tuples_IDs' and column != 'clusterID':\n",
    "            # when normal attributes of the cluster/ dimensions of clusters constructed\n",
    "            # min value equal to tuple's value\n",
    "            attr_range = {\n",
    "                \"min\": new_tuple[column],\n",
    "                \"max\": new_tuple[column]\n",
    "            }\n",
    "            # set the only entry in the new non-ks-cluster to the attribute range\n",
    "            new_non_ks_cluster.at[0, column] = [attr_range]\n",
    "        elif column == 'tuples_IDs':\n",
    "            # if the column to write is the list of associated tuples\n",
    "            # set the tuples ID into the cluster\n",
    "            new_non_ks_cluster.at[0, column] = [new_tuple[\"index\"]]\n",
    "    \n",
    "    new_non_ks_cluster.at[0, 'clusterID'] = new_cluster_index\n",
    "    # add newly created non-ks-cluster to the array\n",
    "    non_ks_clusters.append(new_non_ks_cluster)\n",
    "    #print(\"Successfully created new cluster for tuple ID: \", str(new_tuple[\"index\"]), \" - cluster ID: \", new_cluster_index)\n",
    "    number_of_cluster_indezes += 1\n",
    "    return new_non_ks_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code parts we calculate information loss metrics and enlargement values when tuples are being added to existing clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_loss_cluster(current_cluster):\n",
    "    # calculate the information loss of a specific cluster\n",
    "    \n",
    "    # calculate current info loss\n",
    "    added_loss_values = 0\n",
    "    # calculate current info loss of generalization\n",
    "    for i_c, column in enumerate(current_cluster):\n",
    "        if column != 'tuples_IDs' and column != 'clusterID':\n",
    "            # get the range of the cluster\n",
    "            attr_range = current_cluster.at[0, column]\n",
    "            l_min_value = attr_range[0].get('min', \"0\")\n",
    "            u_max_value = attr_range[0].get('max', \"0\")\n",
    "        \n",
    "            span_current_attr = u_max_value - l_min_value\n",
    "            \n",
    "            U = 255\n",
    "            L = 0\n",
    "            span_domain = U - L # depends on the real data\n",
    "    \n",
    "            info_loss_attr = span_current_attr / span_domain\n",
    "            added_loss_values = added_loss_values + info_loss_attr\n",
    "    # divide by number of attributes (HERE = 6) to obtain info loss of current generalization\n",
    "    added_loss_values = added_loss_values / 6\n",
    "    \n",
    "    return added_loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the enlargement caused when tuple may be added to cluster\n",
    "def enlargement_calculation(new_tuple, non_ks_cluster_item):\n",
    "    # number of attributes\n",
    "    n = 6 # to be adapted to real data, HERE = 6\n",
    "    \n",
    "    ## calculate current info loss\n",
    "    #current_info_loss = info_loss_cluster(current_cluster=non_ks_cluster_item)\n",
    "    \n",
    "    \n",
    "    added_info_loss_values = 0\n",
    "    # calculate current info loss of generalization\n",
    "    for i_c, column in enumerate(non_ks_cluster_item):\n",
    "        if column != 'tuples_IDs' and column != 'clusterID':\n",
    "            # get the range of the cluster\n",
    "            attr_range = non_ks_cluster_item.at[0, column]\n",
    "            l_min_value = attr_range[0].get('min', \"0\")\n",
    "            u_max_value = attr_range[0].get('max', \"0\")\n",
    "        \n",
    "            span_current_attr = u_max_value - l_min_value\n",
    "            \n",
    "            U = 255\n",
    "            L = 0\n",
    "            span_domain = U - L # depends on the real data\n",
    "    \n",
    "            # the current info loss of this attribute\n",
    "            info_loss_current = span_current_attr / span_domain\n",
    "        \n",
    "            # when the tuple would be added:\n",
    "            \n",
    "            # get value of current tuple\n",
    "            tuple_value = new_tuple[column]\n",
    "            # calculate new max ranges\n",
    "            l_new_min_value = min(l_min_value, tuple_value)\n",
    "            u_new_max_value = max(u_max_value, tuple_value)\n",
    "            span_new_current_attr = u_new_max_value - l_new_min_value\n",
    "            # the new info loss of this attribute after adding of the tuple\n",
    "            info_loss_new = span_new_current_attr / span_domain\n",
    "        \n",
    "            # with each dimension/ each attribute add the calculated info loss difference\n",
    "            added_info_loss_values = added_info_loss_values + (info_loss_new - info_loss_current)\n",
    "    \n",
    "    # calculate final enlargement value for adding this tuple to this cluster\n",
    "    # divide by number of attributes (HERE = 6) to obtain info loss of current generalization\n",
    "    added_info_loss_values = added_info_loss_values / n\n",
    "    \n",
    "    #print(\"enlargement value for cluster ID=\", non_ks_cluster_item.at[0,'clusterID'], \"e=\", added_info_loss_values)\n",
    "    \n",
    "    return added_info_loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the enlargement caused when two clusters would be merged\n",
    "def enlargement_clusters_calculation(cluster1, cluster2):\n",
    "    # number of attributes\n",
    "    n = 6 # to be adapted to real data, HERE = 6\n",
    "    \n",
    "    added_info_loss_values = 0\n",
    "    # calculate current info loss of generalization\n",
    "    for i_c, column in enumerate(cluster1):\n",
    "        if column != 'tuples_IDs' and column != 'clusterID':\n",
    "            # get the range of the cluster1\n",
    "            attr_range = cluster1.at[0, column]\n",
    "            l_min_value = attr_range[0].get('min', \"0\")\n",
    "            u_max_value = attr_range[0].get('max', \"0\")\n",
    "        \n",
    "            span_current_attr = u_max_value - l_min_value\n",
    "            \n",
    "            U = 255\n",
    "            L = 0\n",
    "            span_domain = U - L # depends on the real data\n",
    "    \n",
    "            # the current info loss of this attribute\n",
    "            info_loss_current = span_current_attr / span_domain\n",
    "        \n",
    "            # when the second cluster would be added:\n",
    "            \n",
    "            # get range of second cluster\n",
    "            attr_range2 = cluster2.at[0, column]\n",
    "            l_min_value2 = attr_range2[0].get('min', \"0\")\n",
    "            u_max_value2 = attr_range2[0].get('max', \"0\")\n",
    "    \n",
    "            # calculate new min and max ranges\n",
    "            l_new_min_value = min(l_min_value, l_min_value2)\n",
    "            u_new_max_value = max(u_max_value, u_max_value2)\n",
    "            span_new_current_attr = u_new_max_value - l_new_min_value\n",
    "            # the new info loss of this attribute after adding of the second cluster\n",
    "            info_loss_new = span_new_current_attr / span_domain\n",
    "        \n",
    "            # with each dimension/ each attribute add the calculated info loss difference\n",
    "            added_info_loss_values = added_info_loss_values + (info_loss_new - info_loss_current)\n",
    "    \n",
    "    # calculate final enlargement value for adding this cluster to the other cluster\n",
    "    # divide by number of attributes (HERE = 6) to obtain info loss of current generalization\n",
    "    added_info_loss_values = added_info_loss_values / n\n",
    "    \n",
    "    return added_info_loss_values\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following Best-Selection method figures out where to put a new tuple into. It checks whether there is already a cluster whose generalization entails the tuple already or whether a new cluster needs to be generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best selection of a cluster where a tuple can be pushed into\n",
    "def best_selection(new_tuple, k, betha):\n",
    "    # parameter tau can be set initially in main and is influenced by last outputted ks-clusters\n",
    "    # e.g. tau = 10\n",
    "    # parameter betha can be set and influenced\n",
    "    # betha = 5000\n",
    "    global non_ks_clusters\n",
    "    global tau_global\n",
    "    global number_of_cluster_indezes\n",
    "    \n",
    "    #list of minimum enlargement clusters\n",
    "    min_e_clusters = []\n",
    "    min_e = 999999 # set initially the minimum enlargement very high\n",
    "    index_of_current_non_ks_cluster = 0\n",
    "    \n",
    "    for cluster_item in non_ks_clusters:\n",
    "        # calculate enlargement caused by adding tuple\n",
    "        calculated_e = enlargement_calculation(new_tuple, cluster_item)\n",
    "        #print(\"Calculated possible enlargement: \" + str(calculated_e))\n",
    "        if calculated_e < min_e:\n",
    "            # replace the existing clusters in the min e clusters list\n",
    "            min_e_clusters.clear()\n",
    "            min_e_clusters.append(index_of_current_non_ks_cluster)# = calculated_e #[cluster_item] = calculated_e\n",
    "            min_e = calculated_e\n",
    "        else:\n",
    "            if calculated_e == min_e:\n",
    "                # add it to the min e clusters\n",
    "                min_e_clusters.append(index_of_current_non_ks_cluster)# = calculated_e #[cluster_item] = calculated_e\n",
    "                \n",
    "        # increase index of current cluster under observation\n",
    "        index_of_current_non_ks_cluster = index_of_current_non_ks_cluster + 1\n",
    "    \n",
    "    print(\"Calculated min enlargement for tuple:\", str(min_e))\n",
    "    # check whether the current found clusters have enlargement smaller than tau\n",
    "    if min_e <= tau_global:\n",
    "        # return any of the clusters in this list\n",
    "        return non_ks_clusters[random.choice(min_e_clusters)]\n",
    "    else:\n",
    "        # create new cluster if possible\n",
    "        if len(non_ks_clusters) >= betha:\n",
    "            # return any cluster which is minimal because no new cluster can be created\n",
    "            return non_ks_clusters[random.choice(min_e_clusters)]\n",
    "        else:\n",
    "            # create a new cluster\n",
    "            return create_new_cluster(new_tuple, new_cluster_index = number_of_cluster_indezes)#len(non_ks_clusters))\n",
    "    \n",
    "    return \"NULL\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tuple_to_cluster(new_tuple, non_ks_cluster_item):\n",
    "    # add a tuple to the calculated non-ks cluster or ks-cluster (LATER #TO DO)\n",
    "    # calculate span updates of attributes\n",
    "    \n",
    "    # check whether this is not an item for which a new non-ks-cluster\n",
    "    # has been created in this step\n",
    "    if new_tuple[\"index\"] in non_ks_cluster_item.at[0, \"tuples_IDs\"]:\n",
    "        # then skip the \"adding this tuple again\" part and simply return the cluster\n",
    "        return non_ks_cluster_item\n",
    "    \n",
    "    for i_c, column in enumerate(non_ks_cluster_item):\n",
    "        if column != 'tuples_IDs' and column != 'clusterID':\n",
    "            # get the range of the cluster\n",
    "            attr_range = non_ks_cluster_item.at[0, column][0]\n",
    "            min_value = attr_range.get('min', \"0\")\n",
    "            max_value = attr_range.get('max', \"0\")\n",
    "        \n",
    "            # get value of this column of the new tuple to be added\n",
    "            current_value = new_tuple[column]\n",
    "            if min_value > current_value:\n",
    "                # update min if tuple has smaller value\n",
    "                attr_range['min'] = current_value\n",
    "                non_ks_cluster_item.at[0, column] = [attr_range]\n",
    "            if max_value < current_value:\n",
    "                # update max if tuple has smaller value\n",
    "                attr_range['max'] = current_value\n",
    "                non_ks_cluster_item.at[0, column] = [attr_range]\n",
    "        elif column == 'tuples_IDs':\n",
    "            # add tuple ID to the list of tuple ID of this cluster\n",
    "            # set the tuples ID into the cluster\n",
    "            non_ks_cluster_item.at[0, column].append(new_tuple[\"index\"])\n",
    "            \n",
    "            \n",
    "    print(\"Tuple with ID: \" + str(new_tuple[\"index\"]) + \" has been added to an existing non-ks-cluster\")\n",
    "    # return the updated non-ks-cluster\n",
    "    return non_ks_cluster_item\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_tuple_already_outputted(target_count, expiring_tuple_ID):\n",
    "    global output_tuple_max_index\n",
    "    global output_list_of_tuples\n",
    "    #print(\"Output?\", output_tuple_max_index, \"target?\", target_count)\n",
    "    # check whether expiring tuple already outputted or to be outputted now\n",
    "    if expiring_tuple_ID in output_list_of_tuples:\n",
    "        # already output\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    #if output_tuple_max_index < target_count:\n",
    "    #    # has to be outputted\n",
    "    #    return False\n",
    "    #else:\n",
    "    #    # tuple has already been outputted\n",
    "    #    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_size_of_cluster(current_cluster):\n",
    "    global stream_of_tuples\n",
    "    \n",
    "    temp_list = []\n",
    "    unique_tuples_list = [temp_list.append(x) for x in current_cluster.at[0, 'tuples_IDs'] if x not in temp_list]\n",
    "    # count the unique items in the list\n",
    "    size_of_cluster = len(unique_tuples_list)\n",
    "    \n",
    "    if size_of_cluster > 1:\n",
    "        # check whether not a duplet in tuples, meaning that individual MAC address captured several times\n",
    "        distinct_mac_addresses = 0\n",
    "        for one_entry in current_cluster.at[0, 'tuples_IDs']:\n",
    "            #print(one_entry, type(one_entry))\n",
    "            one_tuple = stream_of_tuples[int(one_entry)]\n",
    "            one_tuple_unique = True\n",
    "            for two_entry in current_cluster.at[0, 'tuples_IDs']:\n",
    "                #check that not the same ID\n",
    "                two_tuple = stream_of_tuples[int(two_entry)]\n",
    "                if one_entry != two_entry:\n",
    "                    # check whether values distinct\n",
    "                    if one_tuple[\"one\"] == two_tuple[\"one\"] and one_tuple[\"two\"] == two_tuple[\"two\"] and one_tuple[\"three\"] == two_tuple[\"three\"] and one_tuple[\"four\"] == two_tuple[\"four\"] and one_tuple[\"five\"] == two_tuple[\"five\"] and one_tuple[\"six\"] == two_tuple[\"six\"]:\n",
    "                        # if all are equal then same pid value = not distinct\n",
    "                        one_tuple_unique = False\n",
    "                                         \n",
    "            # only if this one tuple was marked as unique then count it as a distinct MAC address, another distinct entry\n",
    "            if (one_tuple_unique):\n",
    "                distinct_mac_addresses = distinct_mac_addresses + 1\n",
    "            \n",
    "        # the size of a cluster is then the number of distinct mac addresses in the cluster\n",
    "        size_of_cluster = distinct_mac_addresses\n",
    "    #end of if whether size_non_ks_cluster > 1 because the size stays the same if just one tuple in there\n",
    "    \n",
    "    return size_of_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following concentrates on splitting and merging clusters. Clusters need to be merged if they do not fulfill the criteria to be considered a ks-anonymized cluster (e.g., size less than k). Splitting is a task performed in order to increase the quality of the outputted data stream. If clusters are splitted than eventually the information loss of each cluster can be reduced.\n",
    "\n",
    "_Splitting_ \n",
    "\n",
    "_Merging of clusters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import heappush, heappop, heapreplace\n",
    "from functools import total_ordering\n",
    "#following class used to store the tuples with their distance values in the heap\n",
    "@total_ordering\n",
    "class KeyDict(object):\n",
    "    def __init__(self, key, dct):\n",
    "        self.key = key\n",
    "        self.dct = dct\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.key < other#.key\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.key == other#.key\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{0.__class__.__name__}(key={0.key}, dct={0.dct})'.format(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(current_non_ks_cluster, k):\n",
    "    global stream_of_tuples # we need to be able to access every distinct individual tuple with its attributes\n",
    "    global number_of_cluster_indezes # needed in order to create a new cluster which seemleasly integrates into\n",
    "    # set of non-ks-clusters in memory\n",
    "    \n",
    "    print(\"CASTLE - SPLIT requested..\")\n",
    "    \n",
    "    \n",
    "    SC = []\n",
    "    \n",
    "    # as next we need to check that we have k distinct individuals\n",
    "    # we can do this by using one of the pid-Attributes of the tuple\n",
    "    # TODO: adapt to real data use case\n",
    "    \n",
    "    # get the tuple list we need to work on\n",
    "    tuple_list_split_cluster = []\n",
    "    tuple_ID_list = current_non_ks_cluster.at[0, 'tuples_IDs']\n",
    "    for individual_ID in tuple_ID_list:\n",
    "        # search for the corresponding tuple\n",
    "        for fitting_tuple in stream_of_tuples:\n",
    "            if fitting_tuple[\"index\"] == individual_ID:\n",
    "                # tuple found\n",
    "                # save the tuple in the internal tuple list for this splitting function\n",
    "                tuple_list_split_cluster.append(fitting_tuple)#stream_of_tuples)\n",
    "                \n",
    "                break # we can break and escape inner for loop for saving computation\n",
    "                # because once we found the corresponding tuple we can search for the\n",
    "                # next one by directly continuing with the outter for loop\n",
    "    \n",
    "    # now we distribute the tuples over the buckets array BS\n",
    "    # in order to have in each bucket tuples grouped by\n",
    "    # their pid values\n",
    "    BS = []\n",
    "    for individual_tuple in tuple_list_split_cluster:\n",
    "            tuple_has_new_pid = True\n",
    "            # check whether there is already a bucket with this pid value\n",
    "            for single_bucket in BS:\n",
    "                tuple_2 = random.choice(single_bucket)\n",
    "                #check that not the same ID\n",
    "                #print(\"DEBUG: SPLIT: \", individual_tuple, \"tuple_2: \", tuple_2)\n",
    "                if individual_tuple[\"index\"] != tuple_2[\"index\"]:\n",
    "                    # check whether values distinct\n",
    "                    if individual_tuple[\"one\"] == tuple_2[\"one\"] and individual_tuple[\"two\"] == tuple_2[\"two\"] and individual_tuple[\"three\"] == tuple_2[\"three\"] and individual_tuple[\"four\"] == tuple_2[\"four\"] and individual_tuple[\"five\"] == tuple_2[\"five\"] and individual_tuple[\"six\"] == tuple_2[\"six\"]:\n",
    "                        # if all are equal mac address not distinct but equal\n",
    "                        tuple_has_new_pid = False\n",
    "                        # add tuple to this bucket\n",
    "                        ## search in which bucket second tuple is\n",
    "                        #for buckets_item in BS:\n",
    "                        #    if tuple_2 in buckets_item:\n",
    "                        #        # add this tuple into this grouped bucket by pid values\n",
    "                        #        buckets_item.append(individual_tuple)\n",
    "                        #        # automatically BS gets updated by this\n",
    "                        single_bucket.append(individual_tuple)\n",
    "\n",
    "                        break # we can escape the for loop for searching for another match because already added to one bucket with same pid value\n",
    "            # if there was not any other tuple in BS\n",
    "            if (tuple_has_new_pid):\n",
    "                # create a new bucket for this one tuple\n",
    "                BS.append([individual_tuple])\n",
    "\n",
    "    # now BS contains the buckets of tuples grouped by pid values\n",
    "\n",
    "    ## here we can see the list of tuples as the buckets when we\n",
    "    ## assume that they are all with different pid values\n",
    "    #BS = tuple_list_split_cluster\n",
    "    \n",
    "    while len(BS) >= k:\n",
    "    \n",
    "        # we randomly select a bucket with corresponding contained tuples\n",
    "        t_chosen_new_cluster = random.choice(BS)\n",
    "        # we randomly select a tuple of this bucket, called \"t dash\"\n",
    "        t_chosen_tuple = random.choice(t_chosen_new_cluster)\n",
    "        # remove the picked tuple out of list\n",
    "        t_chosen_new_cluster.remove(t_chosen_tuple)\n",
    "        # remove the picked bucket out of list if it got empty\n",
    "        if len(t_chosen_new_cluster) < 1:\n",
    "            BS.remove(t_chosen_new_cluster)\n",
    "        #print(\"t-chosen-new-cluster (t dash) diagnose\", t_chosen_tuple)\n",
    "        # create a new cluster around tuple\n",
    "        C_new = create_new_cluster(new_tuple=t_chosen_tuple, new_cluster_index=(number_of_cluster_indezes+1))\n",
    "        # this new C_new cluster is therefore now also in non-ks-clusters list in memory\n",
    "        # side node: if we have a fast performing server and many new incoming tuples during\n",
    "        # the split function that it might happen that other tuples are also gonna be added to this\n",
    "        # new cluster C_new while computing the split function (but here not of further relevance)\n",
    "        \n",
    "        # next we generate a heap with k-1 nodes (because first tuple is already added to C_new)\n",
    "        # heap creation with instantiation with infinite distances\n",
    "        \n",
    "        # we create a heap with k-1 nodes, initialized with infinite distance to t_dash\n",
    "        heap = []\n",
    "        for x in range(k-1): # iterates from 0 to k-2 meaning we get k-1 nodes into the heap\n",
    "            heappush(heap, KeyDict(9999999, {'1':x})) #int(float('inf')), {'1': x})) # initialized with an infinite value\n",
    "\n",
    "        #print(\"DEBUG: TEST: Key Dict form initialization:\", KeyDict(9999999, {'1':x}))\n",
    "\n",
    "        # for each remaining bucket in BS calulate distances to cluster C_new\n",
    "        # therefore we pick one tuple out of each bucket\n",
    "        for bucket_item in BS:\n",
    "            t_picked_for_comparison = random.choice(bucket_item) # picked t\n",
    "            \n",
    "            # check if distance of this tuple closer to cluster than the one of the heap's root node\n",
    "\n",
    "            # we calculate distance of this tuple to the tuple t_dash:\n",
    "            distance_t = enlargement_calculation(new_tuple=t_picked_for_comparison, non_ks_cluster_item=t_chosen_new_cluster) # here we calculate distance of this tuple to the B_dash cluster\n",
    "\n",
    "            #print(\"DEBUG: heap root:\", heap[0])\n",
    "            # Bugfix: Done: the following if has to be ignored. This is because we add the distances\n",
    "            # one by one into the heap and they get sorted automatically in this python library.\n",
    "            # Therefore we do not have to beat the root node (smallest distance) but it is useful or\n",
    "            # even necessary to also push the other \"infitnite distance\" nodes further down.\n",
    "            #if distance_t < heap[0]:\n",
    "            #distance_t = heapreplace(heap, KeyDict(distance_t, t_picked_for_comparison))\n",
    "            distance_t = heappush(heap, KeyDict(distance_t, t_picked_for_comparison))\n",
    "           \n",
    "\n",
    "        \n",
    "        # after arranging the heap according to min distances/ min enlargements\n",
    "        # iterate over heap and add tuples to C_new\n",
    "        for i in range(k-1):#range(len(heap)): just the top k-1 nodes of the heap of interest\n",
    "            current_heap_node = heappop(heap)\n",
    "            current_t_tilde = current_heap_node.dct\n",
    "\n",
    "            #print(\"DEBUG: Current t_tilde:\", current_t_tilde)\n",
    "            \n",
    "            # insert t_tilde into C_new\n",
    "            C_new = add_tuple_to_cluster(new_tuple=current_t_tilde, non_ks_cluster_item=C_new)\n",
    "            # get bucket where t_tilde was contained and remove t_tilde out of bucket\n",
    "            for bucket_item in BS:\n",
    "                t_tilde_index = current_t_tilde[\"index\"]\n",
    "                for i_tuple in bucket_item:\n",
    "                    if t_tilde_index == i_tuple[\"index\"]:\n",
    "                        bucket_item.remove(current_t_tilde)\n",
    "                        # check if the bucket is empty after removing t_tilde\n",
    "                        if len(bucket_item) < 1:\n",
    "                            # remove bucket\n",
    "                            BS.remove(bucket_item)\n",
    "                        break # we can end the search for the bucket\n",
    "\n",
    "\n",
    "        \n",
    "        # After filling up C_new with enough tuples we can add C_new to SC\n",
    "        SC.append(C_new)\n",
    "    \n",
    "    #print(\"Split: First half of split operation completed, now the remaining tuples will be distributed.\")\n",
    "\n",
    "    # Once less than k tuples/ buckets left we distribute remaining tuples over newly created clusters\n",
    "    for bucket_item in BS:\n",
    "        # for each bucket B_i we take a t_i and see which cluster has min enlargment when adding t_i\n",
    "        # calculate closest cluster to which tuple(s) should be added\n",
    "        # pick a random tuple out of this bucket, called t_i\n",
    "        t_i = random.choice(bucket_item)\n",
    "\n",
    "        # find t_i's nearest cluster meaning minimal enlargement\n",
    "        #list of minimum enlargement clusters\n",
    "        min_e_clusters = []\n",
    "        min_e = 999999 # set initially the minimum enlargement very high\n",
    "        index_of_current_non_ks_cluster = 0\n",
    "        \n",
    "        for cluster_item in SC:\n",
    "            # calculate enlargement caused by adding tuple\n",
    "            calculated_e = enlargement_calculation(t_i, cluster_item)\n",
    "            #print(\"Calculated possible enlargement: \" + str(calculated_e))\n",
    "            if calculated_e < min_e:\n",
    "                # replace the existing clusters in the min e clusters list\n",
    "                min_e_clusters.clear()\n",
    "                min_e_clusters.append(index_of_current_non_ks_cluster)\n",
    "                min_e = calculated_e\n",
    "            else:\n",
    "                if calculated_e == min_e:\n",
    "                    # add it to the min e clusters\n",
    "                    min_e_clusters.append(index_of_current_non_ks_cluster)\n",
    "                    \n",
    "            # increase index of current cluster under observation\n",
    "            index_of_current_non_ks_cluster = index_of_current_non_ks_cluster + 1\n",
    "        \n",
    "        #print(\"Calculated min enlargement for tuple:\", str(min_e))\n",
    "        # get one of these nearest clusters in regard to t_i\n",
    "        nearest_SC_cluster = SC[random.choice(min_e_clusters)]\n",
    "        # add each tuple of current B_i to this chosen cluster\n",
    "        for tuple_within_BS in bucket_item:\n",
    "            # we add tuple to cluster and update it each step with added tuples\n",
    "            nearest_SC_cluster = add_tuple_to_cluster(new_tuple = tuple_within_BS, non_ks_cluster_item = nearest_SC_cluster)\n",
    "            \n",
    "        # after adding all the remaining tuples we can delete this bucket B_i\n",
    "        BS.remove(bucket_item)\n",
    "    # end of for each B_i in BS loop\n",
    "    #print(\"..\")\n",
    "    #print(\"We would like to SPLIT - but to be implemented later\")\n",
    "\n",
    "\n",
    "    # at the end of this split function we need to delete the previous large cluster from memory\n",
    "    # delete cluster C from set of non-ks-clusters\n",
    "    intermediate_index = 0\n",
    "    for cluster_item in non_ks_clusters: # maybe the for loop and if are not needed if removing of cluster works\n",
    "        if cluster_item.at[0, 'clusterID'] == current_non_ks_cluster.at[0, 'clusterID']:\n",
    "            #print(\"Remove cluster ID = \", cluster_item.at[0, 'clusterID'], \" from non-ks-cluster set.\")\n",
    "            del non_ks_clusters[intermediate_index]\n",
    "        intermediate_index += 1\n",
    "\n",
    "    print(\"Splitting completed. We have \", len(SC), \"new clusters after the split operation.\")\n",
    "    \n",
    "    return SC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_clusters(expiring_cluster, set_of_other_clusters, k):\n",
    "    global non_ks_clusters\n",
    "    \n",
    "    merged_clusters = expiring_cluster\n",
    "    while calculate_size_of_cluster(merged_clusters) < k:\n",
    "        min_enlargement = 100000000 # high number\n",
    "        min_enlargement_cluster = set_of_other_clusters[0]\n",
    "        # for each cluster calculate the enlargement when merged together\n",
    "        for cluster_item in set_of_other_clusters:\n",
    "            # calculate possible enlargement when merging clusters\n",
    "            \n",
    "            current_e = enlargement_clusters_calculation(cluster1=merged_clusters, cluster2=cluster_item)\n",
    "            \n",
    "            if current_e < min_enlargement:\n",
    "                min_enlargement_cluster = cluster_item\n",
    "        \n",
    "        # merge the cluster with this new min enlargement cluster\n",
    "        for i_c, column in enumerate(merged_clusters):\n",
    "            if column != 'tuples_IDs' and column != 'clusterID':\n",
    "                # get the range of the cluster\n",
    "                attr_range = merged_clusters.at[0, column][0]\n",
    "                min_value = attr_range.get('min', \"0\")\n",
    "                max_value = attr_range.get('max', \"0\")\n",
    "                # get the range of the to be added cluster\n",
    "                attr_range2 = min_enlargement_cluster.at[0, column][0]\n",
    "                min_value2 = attr_range2.get('min', \"0\")\n",
    "                max_value2 = attr_range2.get('max', \"0\")\n",
    "        \n",
    "                if min_value > min_value2:\n",
    "                    # update min if new cluster has smaller value\n",
    "                    attr_range['min'] = min_value2\n",
    "                    merged_clusters.at[0, column] = [attr_range]\n",
    "                if max_value < max_value2:\n",
    "                    # update max if new cluster has higher value\n",
    "                    attr_range['max'] = max_value2\n",
    "                    merged_clusters.at[0, column] = [attr_range]\n",
    "            elif column == 'tuples_IDs':\n",
    "                # add tuple ID to the list of tuple ID of this cluster\n",
    "                merged_clusters.at[0, column].extend(min_enlargement_cluster.at[0, column])\n",
    "        \n",
    "        # delete min enlargement cluster from set of other clusters\n",
    "        intermediate_index = 0\n",
    "        for cluster_item in set_of_other_clusters: # maybe the for loop and if are not needed if removing of cluster works\n",
    "            if cluster_item.at[0, 'clusterID'] == min_enlargement_cluster.at[0, 'clusterID']:\n",
    "                del set_of_other_clusters[intermediate_index]\n",
    "            intermediate_index += 1\n",
    "            \n",
    "        # delete min enlargement cluster from set of non-ks-clusters\n",
    "        intermediate_index = 0\n",
    "        for cluster_item in non_ks_clusters: # maybe the for loop and if are not needed if removing of cluster works\n",
    "            if cluster_item.at[0, 'clusterID'] == min_enlargement_cluster.at[0, 'clusterID']:\n",
    "                #print(\"Remove cluster ID = \", cluster_item.at[0, 'clusterID'], \" from non-ks-cluster set.\")\n",
    "                del non_ks_clusters[intermediate_index]\n",
    "            intermediate_index += 1\n",
    "        \n",
    "        print(\"..successfully merged cluster ID = \", min_enlargement_cluster.at[0, 'clusterID'], \" to the current cluster..\")\n",
    "    \n",
    "    return merged_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following concentrates on the outputting of clusters.\n",
    "_The special case of outputting is suppression when the most general generalization needs to be applied._\n",
    "The methods thereafter simply concentrate on outputting the tuples already generalized with their respective cluster generalizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the tuple as generalization in csv file\n",
    "def official_outputting(generalization): \n",
    "    #print(\"Saving to file..\")\n",
    "    with open(\"generalization_output.txt\", \"a\") as f:\n",
    "        f.write(generalization + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression of tuple if no cluster generalization can be applied\n",
    "def suppress_tuple(single_tuple):\n",
    "    global non_ks_clusters\n",
    "    \n",
    "    # Output\n",
    "    output_string = \"\"\n",
    "    # build the current attribute string\n",
    "    for i_c, column in enumerate(single_tuple):\n",
    "        if column != 'tuples_IDs' and column != 'clusterID':\n",
    "            output_string = output_string + str(column) + \",\"\n",
    "                \n",
    "    output_string = output_string + \" with G=[]\"\n",
    "    \n",
    "    # build the generalization string\n",
    "    generalization_string = \"\"\n",
    "    generalization_string = \"[\" + str(0) + \"-\" + str(255) + \"]\"\n",
    "    generalization_string = generalization_string + \"[\" + str(0) + \"-\" + str(255) + \"]\"\n",
    "    generalization_string = generalization_string + \"[\" + str(0) + \"-\" + str(255) + \"]\"\n",
    "    generalization_string = generalization_string + \"[\" + str(0) + \"-\" + str(255) + \"]\"\n",
    "    generalization_string = generalization_string + \"[\" + str(0) + \"-\" + str(255) + \"]\"\n",
    "    generalization_string = generalization_string + \"[\" + str(0) + \"-\" + str(255) + \"]\"\n",
    "    \n",
    "    output_string = output_string + generalization_string\n",
    "    \n",
    "    print(\"Output of Tuple ID =\",str(single_tuple[\"index\"]), \":\", output_string)\n",
    "    \n",
    "    #official_outputting(generalization = generalization_string) # saving to output file\n",
    "    \n",
    "    # save tuple as already outputted:\n",
    "    output_list_of_tuples.append(single_tuple[\"index\"])\n",
    "    \n",
    "    # delete non-ks-cluster entries the tuple was inside beforehand\n",
    "    intermediate_index = 0\n",
    "    for cluster_item in non_ks_clusters:\n",
    "        for i_c, column in enumerate(cluster_item):\n",
    "            # delete the tuple ID out of this cluster\n",
    "            if column == 'tuples_IDs':\n",
    "                if single_tuple[\"index\"] in cluster_item.at[0, column]:\n",
    "                    # delete tuple out of this list\n",
    "                    cluster_item.at[0, column].remove(single_tuple[\"index\"])\n",
    "                    # if the non-ks-cluster had only this single tuple inside then delete cluster\n",
    "                    if len(cluster_item.at[0, column]) == 0:\n",
    "                        # delete the cluster from the non-ks-anonymized cluster set\n",
    "                        print(\"Remove cluster ID = \", cluster_item.at[0, 'clusterID'], \" from non-ks-cluster set.\")\n",
    "                        del non_ks_clusters[intermediate_index]\n",
    "        intermediate_index += 1\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_with_generalization(single_tuple, generalization_cluster):\n",
    "    # output a single tuple with a given generalization of a cluster\n",
    "    global non_ks_clusters\n",
    "    global output_list_of_tuples\n",
    "    \n",
    "    \n",
    "    output_string = \"\"\n",
    "    # build the current attribute string\n",
    "    for i_c, column in enumerate(single_tuple):\n",
    "        if column != 'tuples_IDs' and column != 'clusterID':\n",
    "            output_string = output_string + str(column) + \",\"\n",
    "                \n",
    "    output_string = output_string + \" with G=[]\"\n",
    "            \n",
    "    # build the generalization string\n",
    "    generalization_string = \"\"\n",
    "    for i_c, column in enumerate(generalization_cluster):\n",
    "        if column != 'tuples_IDs' and column != 'clusterID':\n",
    "            # get the range of the cluster\n",
    "            attr_range = generalization_cluster.at[0, column][0]\n",
    "            min_value = attr_range.get('min', \"0\")\n",
    "            max_value = attr_range.get('max', \"0\")\n",
    "            generalization_string = generalization_string + \"[\" + str(min_value) + \"-\" + str(max_value) + \"]\"\n",
    "    output_string = output_string + generalization_string\n",
    "    print(\"Output of Tuple ID =\",str(single_tuple[\"index\"]), \":\", output_string)\n",
    "    \n",
    "    #official_outputting(generalization = generalization_string) # output to file\n",
    "    \n",
    "    # save tuple as already outputted:\n",
    "    output_list_of_tuples.append(single_tuple[\"index\"])\n",
    "    \n",
    "    # delete non-ks-cluster entries the tuple was inside beforehand\n",
    "    intermediate_index = 0\n",
    "    for cluster_item in non_ks_clusters:\n",
    "        for i_c, column in enumerate(cluster_item):\n",
    "            # delete the tuple ID out of this cluster\n",
    "            if column == 'tuples_IDs':\n",
    "                if single_tuple[\"index\"] in cluster_item.at[0, column]:\n",
    "                    # delete tuple out of this list\n",
    "                    cluster_item.at[0, column].remove(single_tuple[\"index\"])\n",
    "                    # if the non-ks-cluster had only this single tuple inside then delete cluster\n",
    "                    if len(cluster_item.at[0, column]) == 0:\n",
    "                        # delete the cluster from the non-ks-anonymized cluster set\n",
    "                        #intermediate_index = 0\n",
    "                        #for cluster_item_2 in non_ks_clusters:\n",
    "                        #    if cluster_item_2.at[0, 'clusterID'] == single_C_i.at[0, 'clusterID']:\n",
    "                        print(\"Remove cluster ID = \", cluster_item.at[0, 'clusterID'], \" from non-ks-cluster set.\")\n",
    "                        del non_ks_clusters[intermediate_index]\n",
    "        intermediate_index += 1\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_cluster(current_non_ks_cluster, current_size_cluster, stream_of_tuples,  k, my):\n",
    "    global ks_clusters # the already outputted ks-anonymized clusters\n",
    "    global tau_global\n",
    "    global non_ks_clusters\n",
    "    global output_list_of_tuples\n",
    "    \n",
    "    # set of clusters returned by splitting cluster\n",
    "    SC = []\n",
    "    \n",
    "    # let's check whether cluster can be split\n",
    "    if current_size_cluster >= 2*k:\n",
    "        SC = split(current_non_ks_cluster=current_non_ks_cluster, k=k)\n",
    "    else:\n",
    "        # cluster can not be split\n",
    "        SC = [current_non_ks_cluster]\n",
    "        \n",
    "    for single_C_i in SC:\n",
    "        # output all tuples in this cluster with its generalization\n",
    "        print(\"we are about to output the cluster with ID \", str(single_C_i.at[0, 'clusterID']))\n",
    "        \n",
    "        # TODO with real outputting (when PRODUCTION ready)\n",
    "        \n",
    "        # output each tuple\n",
    "        for single_tuple_ID in single_C_i.at[0, 'tuples_IDs']:\n",
    "            current_tuple = stream_of_tuples[single_tuple_ID]\n",
    "                  \n",
    "            output_string = \"\"\n",
    "            # build the current attribute string\n",
    "            for i_c, column in enumerate(current_tuple):\n",
    "                if column != 'tuples_IDs' and column != 'clusterID':\n",
    "                    output_string = output_string + str(column) + \",\"\n",
    "                \n",
    "            output_string = output_string + \" with G=[]\"\n",
    "             \n",
    "             # build the generalization string\n",
    "            generalization_string = \"\"\n",
    "            for i_c, column in enumerate(single_C_i):\n",
    "                if column != 'tuples_IDs' and column != 'clusterID':\n",
    "                    # get the range of the cluster\n",
    "                    attr_range = single_C_i.at[0, column][0]\n",
    "                    min_value = attr_range.get('min', \"0\")\n",
    "                    max_value = attr_range.get('max', \"0\")\n",
    "                    generalization_string = generalization_string + \"[\" + str(min_value) + \"-\" + str(max_value) + \"]\"\n",
    "            output_string = output_string + generalization_string\n",
    "            print(\"Output of Tuple ID =\",str(current_tuple[\"index\"]), \":\", output_string)\n",
    "            \n",
    "            # save outputted tuple as outputted\n",
    "            output_list_of_tuples.append(single_tuple_ID)\n",
    "            #print(\"output list of tuples:\", output_list_of_tuples)\n",
    "            # TODO delete tuple out of maybe existing clusters??\n",
    "            \n",
    "            #output_with_generalization(single_tuple=current_tuple, generalization_cluster=single_C_i)\n",
    "            \n",
    "            #official_outputting(generalization = generalization_string) # output to file\n",
    "            \n",
    "            \n",
    "        \n",
    "        # update tau according to InfoLoss(of this cluster)\n",
    "        #calculate how many last ks-clusters can be viewed (depending on my and the number of existing ones)\n",
    "        # upper-bound minus one because the last to be calculated cluster is the current one which is\n",
    "        # not already in the outputted ks-clusters\n",
    "        upper_bound = min(my-1, len(ks_clusters)-1)\n",
    "        intermediate_result = info_loss_cluster(single_C_i)\n",
    "        if upper_bound >= 0: # catch division by zero in the beginning when there's no ks-cluster yet created\n",
    "            for i in range (0, upper_bound):\n",
    "                # take the last my-1 (because current one also observed) clusters\n",
    "                intermediate_result += info_loss_cluster(ks_clusters[len(ks_clusters)-1-i])\n",
    "            # calculate average info loss\n",
    "            intermediate_result = intermediate_result / (upper_bound + 1)\n",
    "            # originally divided by my but since in beginning not enough ks-clusters we have to look at min(..)\n",
    "        tau_global = intermediate_result\n",
    "        print(\"param:tau_global updated to: \", tau_global, \" and last generalization had info loss:\", info_loss_cluster(single_C_i))\n",
    "        \n",
    "        if info_loss_cluster(single_C_i) <= tau_global:\n",
    "            # insert this cluster as a good cluster into the set of ks-anonymized clusters\n",
    "            \n",
    "            # create new cluster\n",
    "            #new_ks_cluster = pd.DataFrame(columns=column_names_cluster)\n",
    "            #print(\"single_c_i:\", single_C_i)\n",
    "            #new_ks_cluster = single_C_i\n",
    "            #print(\"We can store this good non-ks-anonymized cluster ID = \", single_C_i.at[0, 'clusterID'], \" as ks-cluster\")\n",
    "            ks_clusters.append(single_C_i)\n",
    "            print(\"Successfully created ks-anonymized cluster ID: \",str(single_C_i.at[0, 'clusterID']))\n",
    "            #print(\"new cluster to be: \",new_ks_cluster)\n",
    "            #print(\"ks-clusters:\",ks_clusters)\n",
    "           \n",
    "            \n",
    "            # if the info loss to large then do not save this cluster in ks-anonymized cluster set (info loss too bad)\n",
    "        \n",
    "        \n",
    "        # delete the cluster from the non-ks-anonymized cluster set\n",
    "        intermediate_index = 0\n",
    "        for cluster_item in non_ks_clusters: # maybe the for loop and if are not needed if removing of cluster works\n",
    "            if cluster_item.at[0, 'clusterID'] == single_C_i.at[0, 'clusterID']:\n",
    "                print(\"We can remove the cluster ID = \", single_C_i.at[0, 'clusterID'], \" from the non-ks-cluster set.\")\n",
    "                del non_ks_clusters[intermediate_index]\n",
    "            intermediate_index += 1\n",
    "                #non_ks_clusters.remove#(single_C_i) if single_C_i in non_ks_clusters else None\n",
    "            \n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As next we have the delay_constraint function which handles expiring tuples that need to be outputted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling of an expiring tuple which has to be outputted\n",
    "def delay_constraint(expiring_tuple, stream_of_tuples, k, my):\n",
    "    global non_ks_clusters\n",
    "    global ks_clusters\n",
    "    \n",
    "    # current non-ks-cluster the tuple belongs to\n",
    "    current_cluster = non_ks_clusters[0] # initialize with anything, can also be empty\n",
    "    # get current cluster the tuple is in\n",
    "    #cluster_index_tuple = -1\n",
    "    for cluster_item in non_ks_clusters:\n",
    "        for one_ID in cluster_item.at[0, 'tuples_IDs']:\n",
    "            if one_ID == expiring_tuple[\"index\"]:\n",
    "                #cluster_index_tuple = cluster_item.at[0, 'clusterID']\n",
    "                #save this cluster as the cluster this tuple belongs to\n",
    "                current_cluster = cluster_item\n",
    "    temp_list = []\n",
    "    unique_tuples_list = [temp_list.append(x) for x in current_cluster.at[0, 'tuples_IDs'] if x not in temp_list]\n",
    "    # count the unique items in the list\n",
    "    size_non_ks_cluster = len(unique_tuples_list)\n",
    "    \n",
    "    if size_non_ks_cluster > 1:\n",
    "        # check whether not a duplet in tuples, meaning that individual pid values captured several times\n",
    "        distinct_pid_values = 0\n",
    "        for one_entry in current_cluster.at[0, 'tuples_IDs']:\n",
    "            #print(one_entry, type(one_entry))\n",
    "            one_tuple = stream_of_tuples[int(one_entry)]\n",
    "            one_tuple_unique = True\n",
    "            for two_entry in current_cluster.at[0, 'tuples_IDs']:\n",
    "                # check that not the same ID\n",
    "                if one_entry != two_entry:\n",
    "                    two_tuple = stream_of_tuples[int(two_entry)]\n",
    "                    # check whether values distinct\n",
    "                    if one_tuple[\"one\"] == two_tuple[\"one\"] and one_tuple[\"two\"] == two_tuple[\"two\"] and one_tuple[\"three\"] == two_tuple[\"three\"] and one_tuple[\"four\"] == two_tuple[\"four\"] and one_tuple[\"five\"] == two_tuple[\"five\"] and one_tuple[\"six\"] == two_tuple[\"six\"]:\n",
    "                        # if all are equal then not distinct\n",
    "                        one_tuple_unique = False\n",
    "                                         \n",
    "            # only if this one tuple was marked as unique then count it as a distinct pid value, another distinct entry\n",
    "            if (one_tuple_unique):\n",
    "                distinct_pid_values = distinct_pid_values + 1\n",
    "        \n",
    "        if distinct_pid_values == 0:\n",
    "            distinct_pid_values = 1 # at least one pid value is in cluster if there are tuples contained\n",
    "   \n",
    "        # the size of a cluster is then the number of distinct pid values in the cluster\n",
    "        size_non_ks_cluster = distinct_pid_values\n",
    "    #end of if whether size_non_ks_cluster > 1 because the size stays the same if just one tuple in there\n",
    "    \n",
    "    print(\"size_non_ks_cluster:\", size_non_ks_cluster)\n",
    "    \n",
    "    if size_non_ks_cluster >= k:\n",
    "        # output the cluster\n",
    "        \n",
    "        output_cluster(current_non_ks_cluster=current_cluster, current_size_cluster=size_non_ks_cluster, stream_of_tuples=stream_of_tuples, k= k, my=my)\n",
    "        \n",
    "    else: \n",
    "        \n",
    "        #print(\"... tuple not ready to be outputted yet (non-ks-cluster size not large enough) ...\")\n",
    "        \n",
    "        # check whether expiring tuple contained in a ks-anonymized cluster\n",
    "        # if so then select one of them randomly and output and remove from current non-ks-cluster\n",
    "        \n",
    "        # set of possible ks-clusters, initialized to be empty\n",
    "        possible_ks_clusters = []\n",
    "        # check for each ks-cluster\n",
    "        for current_ks_cluster in ks_clusters:\n",
    "            #print(\"current looking at ks cluster\", current_ks_cluster)\n",
    "            possible_fit = True\n",
    "            # check for each attribute\n",
    "            for i_c, column in enumerate(current_ks_cluster):\n",
    "                if column != 'tuples_IDs' and column != 'clusterID':\n",
    "                    # get the range of the cluster\n",
    "                    attr_range = current_ks_cluster.at[0, column]\n",
    "                    min_value = attr_range[0].get('min', \"0\")\n",
    "                    max_value = attr_range[0].get('max', \"0\")\n",
    "                    \n",
    "                    # get value of current expiring tuple\n",
    "                    current_value = expiring_tuple[column]\n",
    "                    \n",
    "                    # if within range then okay\n",
    "                    # if not then ks-cluster not fitting\n",
    "                    if current_value > max_value or current_value < min_value:\n",
    "                        possible_fit = False\n",
    "            if possible_fit == True:\n",
    "                possible_ks_clusters.append(current_ks_cluster)\n",
    "        \n",
    "        #print(\"# possible ks-clusters containing tuple:\", len(possible_ks_clusters))\n",
    "        # check whether the set of fitting ks-anonymized clusters is not empty\n",
    "        if len(possible_ks_clusters) > 0:\n",
    "            # there are fitting ks-anonymized clusters for this tuple\n",
    "            random_ks_cluster = random.choice(possible_ks_clusters)\n",
    "            # we can output this tuple with the cluster \n",
    "            output_with_generalization(single_tuple=expiring_tuple, generalization_cluster=random_ks_cluster)\n",
    "            \n",
    "            return \"NULL\"\n",
    "        \n",
    "        calc_total_tuples_in_non_ks_clusters = 0\n",
    "        m = 0\n",
    "        # check for each non-ks-anonymized cluster\n",
    "        for cluster_item in non_ks_clusters:\n",
    "            # calculate size of this cluster_item\n",
    "            size_other_cluster = calculate_size_of_cluster(current_cluster = cluster_item)\n",
    "            \n",
    "            calc_total_tuples_in_non_ks_clusters += size_other_cluster\n",
    "            \n",
    "            # check if cluster size larger than current cluster\n",
    "            if size_non_ks_cluster < size_other_cluster:\n",
    "                m = m+1\n",
    "        if m > (len(non_ks_clusters)/2):\n",
    "            ## Description of this case: \n",
    "            ## If the expiring cluster is smaller than (len(non_ks_clusters)/2) existing non-ks-anonmized clusters\n",
    "            ## in size, it is regarded as an outlier. In this case, CASTLE suppresses t, that is, it outputs t\n",
    "            ## with the most generalized QI value.\n",
    "            \n",
    "            # suppress tuple t\n",
    "            \n",
    "            print(\"We need to suppress this current tuple..\")\n",
    "            suppress_tuple(single_tuple=expiring_tuple)\n",
    "            #print(\"Output of Tuple ID =\",str(expiring_tuple[\"index\"]), \":\" + \"  MOST GENERAL GENERALIZATION\")\n",
    "            \n",
    "            return \"NULL\"\n",
    "        \n",
    "        \n",
    "        ## Description of this case:\n",
    "        ## As the last alternative, procedure delay constraint() verifies whether a merge among C\n",
    "        ## and some of the other non-ks-anonymized clusters is possible. Notice that, if the total\n",
    "        ## size of all clusters in ks_clusters is fewer than k (step 17), a merge operation would\n",
    "        ## not generate a cluster with the size at least k. Therefore, the only way to output the\n",
    "        ## expiring tuple is suppressing it (step 18). Otherwise, the merge can take place (step 20)\n",
    "        if (calc_total_tuples_in_non_ks_clusters < k):\n",
    "            # suppress tuple t\n",
    "            print(\"We need to suppress this current tuple..\")\n",
    "            suppress_tuple(single_tuple=expiring_tuple)\n",
    "            \n",
    "            return \"NULL\"\n",
    "        \n",
    "        \n",
    "        # otherwise we need to merge clusters\n",
    "        #print(\"We need to merge some clusters..\")\n",
    "        # get all non-ks-anonymized clusters without current_cluster\n",
    "        other_clusters = []\n",
    "        for current_non_ks_cluster in non_ks_clusters:\n",
    "            if current_non_ks_cluster.at[0, 'clusterID'] != current_cluster.at[0, 'clusterID']:\n",
    "                other_clusters.append(current_non_ks_cluster)\n",
    "        MC = merge_clusters(expiring_cluster=current_cluster, set_of_other_clusters=other_clusters, k=k)\n",
    "        MC_size_cluster = calculate_size_of_cluster(current_cluster=MC)\n",
    "        output_cluster(current_non_ks_cluster=MC, current_size_cluster=MC_size_cluster, stream_of_tuples=stream_of_tuples,  k=k, my=my)\n",
    "    \n",
    "    return \"NULL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Main function of CASTLE</h3>\n",
    "Firstly the main CASTLE function which takes a new tuple as input and if there is a tuple which needs to be outputted then it outputs the expiring tuple as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_position_of_stream = 0\n",
    "stream_of_tuples = []\n",
    "\n",
    "#save the highest number of outputted tuple\n",
    "output_tuple_max_index = -1\n",
    "\n",
    "# save list of outputted tuples\n",
    "output_list_of_tuples = []\n",
    "\n",
    "# cluster indexes supposed to be increasing\n",
    "number_of_cluster_indezes = 0\n",
    "\n",
    "def CASTLE_main(new_tuple, k, delay_counts, tau_param, my, betha):\n",
    "    global non_ks_clusters\n",
    "    # current position of tuple\n",
    "    global current_position_of_stream\n",
    "    current_position_of_stream = new_tuple[\"index\"]\n",
    "    \n",
    "    # set the initial value for the tau for the start, later on updated on recent my outputted ks-clusters\n",
    "    global tau_global\n",
    "    tau_global = tau_param\n",
    "    \n",
    "    \n",
    "    # add new tuple to our local memory repository of stream received = input stream tuples\n",
    "    stream_of_tuples.append(new_tuple)\n",
    "    \n",
    "    # PART I\n",
    "    \n",
    "    # check whether we already have clusters to put tuple into\n",
    "    if not non_ks_clusters:\n",
    "        create_new_cluster(new_tuple, new_cluster_index = number_of_cluster_indezes)#len(non_ks_clusters))\n",
    "    else:\n",
    "        # for the new tuple check whether a good cluster exists for it\n",
    "        cluster_good = best_selection(new_tuple, k=k, betha=betha)\n",
    "        #if cluster_good == None:\n",
    "        # create new cluster\n",
    "        #create_new_cluster(new_tuple, new_cluster_index = len(non_ks_clusters))\n",
    "        #else:\n",
    "        # add to the best fitting cluster\n",
    "        # get index of this fitting cluster within non-ks-clusters\n",
    "        index_cluster_good = cluster_good.at[0, 'clusterID']\n",
    "        updated_cluster_good = add_tuple_to_cluster(new_tuple, cluster_good)\n",
    "        # update the returned cluster\n",
    "        for current_non_ks_cluster in non_ks_clusters:\n",
    "            if current_non_ks_cluster.at[0, 'clusterID'] == index_cluster_good:\n",
    "                current_non_ks_cluster = updated_cluster_good\n",
    "        #non_ks_clusters[index_cluster_good] = updated_cluster_good\n",
    "        \n",
    "    # PART II\n",
    "    \n",
    "    # check whether there exists an expiring tuple\n",
    "    target_count = int(current_position_of_stream - delay_counts)\n",
    "    # only output if there are at least delay counts tuples beforehand present\n",
    "    # basically handle case that in the very beginning there cannot be outputted any tuple before\n",
    "    if target_count >= 0:\n",
    "        #print(\"We test expiring tuple ID: \", target_count)\n",
    "        if not check_tuple_already_outputted(target_count, expiring_tuple_ID=target_count):\n",
    "            # we have to make sure that expiring tuples are outputted\n",
    "            delay_constraint(stream_of_tuples[target_count], stream_of_tuples=stream_of_tuples, k=k, my=my)\n",
    "        else:\n",
    "            print(\"..this tuple has already been outputted before\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>TESTING\n",
    "Functionality of CASTLE</h2>\n",
    "<i>Please be aware of the fact that in order to test the functionality corrctly it may be needed to re-run the whole\n",
    "notebook because it can be that otherwise the non-ks-anonymized clusters persist in memory of previous insertions\n",
    "which is in reality not the case. Thanks. :) </i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some functions to visualize the output of our tests better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPROVED VISUALIZATION OF OUTPUT\n",
    "\n",
    "def printCluster(clusters_to_output):\n",
    "    output_string = \"\"\n",
    "            \n",
    "    # for each cluster to be outputted\n",
    "    for cluster_item in clusters_to_output:\n",
    "        # build the generalization string\n",
    "        output_string = output_string + \"G=[] \"\n",
    "        for i_c, column in enumerate(cluster_item):\n",
    "            if column != 'tuples_IDs' and column != 'clusterID':\n",
    "                # get the range of the cluster\n",
    "                attr_range = cluster_item.at[0, column][0]\n",
    "                min_value = attr_range.get('min', \"0\")\n",
    "                max_value = attr_range.get('max', \"0\")\n",
    "                output_string = output_string + \"[\" + str(min_value) + \"-\" + str(max_value) + \"]\"\n",
    "            if column == 'tuples_IDs':\n",
    "                output_string = output_string + \"tupleIDs[\" + str(cluster_item.at[0, column]) + \"]\"\n",
    "            if column == 'clusterID':\n",
    "                output_string = output_string + \"clusterID =[\" + str(cluster_item.at[0, column]) + \"]\"\n",
    "           \n",
    "        output_string = output_string + \"\\n\"\n",
    "\n",
    "    return output_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual TESTS follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_environment():\n",
    "    # reset the non-ks-clusters in memory\n",
    "    global non_ks_clusters\n",
    "    non_ks_clusters = []\n",
    "    # reset the generated ks-clusters\n",
    "    global ks_clusters\n",
    "    ks_clusters = []\n",
    "    global current_position_of_stream\n",
    "    current_position_of_stream = 0\n",
    "    global stream_of_tuples\n",
    "    stream_of_tuples = []\n",
    "    global output_tuple_max_index\n",
    "    output_tuple_max_index = -1\n",
    "    global output_list_of_tuples\n",
    "    output_list_of_tuples = []\n",
    "    global number_of_cluster_indezes\n",
    "    number_of_cluster_indezes = 0\n",
    "    \n",
    "def reset_df(new_df):\n",
    "    global df\n",
    "    df = new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING\n",
    "# FUNCTIONALITY OF CASTLE\n",
    "\n",
    "def testing():\n",
    "    reset_environment()\n",
    "\n",
    "    # \"streaming\" the first tuples to the CASTLE anonymization function\n",
    "\n",
    "    for x in range(100): # do for 0..99\n",
    "        # get data from sample MAC list input\n",
    "        get_tuple = df.iloc[x]\n",
    "        get_tuple[\"index\"] = x\n",
    "        print(\"+++++++++++ We give the CASTLE algorithm the next tuple (\", x, \") +++++++++++++++\")\n",
    "        # call CASTLE main function\n",
    "        CASTLE_main(get_tuple, k=2, delay_counts=5, tau_param=0.2, betha= 5000, my=5)\n",
    "\n",
    "    # output non-ks-clusters\n",
    "    print(\"--> --> --> --> --> --> --> CASTLE rounds are over --> --> --> --> --> --> -->\")\n",
    "    print(\"--> Output the non-ks-clusters in memory: \\n\", printCluster(clusters_to_output=non_ks_clusters))\n",
    "    print(\"--> Output the ks-clusters reusable: \\n\", printCluster(clusters_to_output=ks_clusters))\n",
    "    print(\"Number of non-ks-clusters (not yet outputted): \" + str(len(non_ks_clusters)))\n",
    "    print(\"Number of re-usuable ks-clusters outputted: \" + str(len(ks_clusters)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christian\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\Christian\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:915: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.loc[key] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 0 ) +++++++++++++++\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 1 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.25490196078431376\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 2 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.2405228758169935\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 3 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.1758169934640523\n",
      "Tuple with ID: 3 has been added to an existing non-ks-cluster\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 4 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.32679738562091504\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 5 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.19869281045751633\n",
      "Tuple with ID: 5 has been added to an existing non-ks-cluster\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  3  to the current cluster..\n",
      "we are about to output the cluster with ID  0\n",
      "Output of Tuple ID = 0 : 102,179,254,104,136,185,0, with G=[][102-110][18-179][108-254][33-104][136-147][16-185]\n",
      "Output of Tuple ID = 4 : 110,18,108,33,147,16,4, with G=[][102-110][18-179][108-254][33-104][136-147][16-185]\n",
      "param:tau_global updated to:  0.36993464052287583  and last generalization had info loss: 0.36993464052287583\n",
      "Successfully created ks-anonymized cluster ID:  0\n",
      "We can remove the cluster ID =  0  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 6 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.12483660130718954\n",
      "Tuple with ID: 6 has been added to an existing non-ks-cluster\n",
      "size_non_ks_cluster: 4\n",
      "CASTLE - SPLIT requested..\n",
      "Tuple with ID: 1 has been added to an existing non-ks-cluster\n",
      "Tuple with ID: 3 has been added to an existing non-ks-cluster\n",
      "Splitting completed. We have  2 new clusters after the split operation.\n",
      "we are about to output the cluster with ID  5\n",
      "Output of Tuple ID = 5 : 112,68,26,217,83,215,5, with G=[][112-208][68-150][26-151][166-217][83-195][215-216]\n",
      "Output of Tuple ID = 1 : 208,150,151,166,195,216,1, with G=[][112-208][68-150][26-151][166-217][83-195][215-216]\n",
      "param:tau_global updated to:  0.3052287581699346  and last generalization had info loss: 0.3052287581699346\n",
      "Successfully created ks-anonymized cluster ID:  5\n",
      "We can remove the cluster ID =  5  from the non-ks-cluster set.\n",
      "we are about to output the cluster with ID  6\n",
      "Output of Tuple ID = 6 : 160,101,149,130,202,31,6, with G=[][160-214][101-148][55-149][105-130][130-202][31-255]\n",
      "Output of Tuple ID = 3 : 214,148,55,105,130,255,3, with G=[][160-214][101-148][55-149][105-130][130-202][31-255]\n",
      "param:tau_global updated to:  0.32124183006535945  and last generalization had info loss: 0.3372549019607843\n",
      "We can remove the cluster ID =  6  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 7 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.20980392156862746\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  6  to the current cluster..\n",
      "we are about to output the cluster with ID  2\n",
      "Output of Tuple ID = 2 : 224,102,254,35,45,194,2, with G=[][224-240][102-137][236-254][11-35][45-115][36-194]\n",
      "Output of Tuple ID = 7 : 240,137,236,11,115,36,7, with G=[][224-240][102-137][236-254][11-35][45-115][36-194]\n",
      "param:tau_global updated to:  0.257516339869281  and last generalization had info loss: 0.20980392156862746\n",
      "Successfully created ks-anonymized cluster ID:  2\n",
      "We can remove the cluster ID =  2  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 8 ) +++++++++++++++\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 9 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.22549019607843138\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 10 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.22352941176470587\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 11 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.24183006535947713\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 12 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.3424836601307189\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 13 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.27385620915032677\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  12  to the current cluster..\n",
      "we are about to output the cluster with ID  7\n",
      "Output of Tuple ID = 8 : 237,54,187,81,89,210,8, with G=[][2-237][54-70][133-187][41-81][89-161][208-210]\n",
      "Output of Tuple ID = 13 : 2,70,133,41,161,208,13, with G=[][2-237][54-70][133-187][41-81][89-161][208-210]\n",
      "param:tau_global updated to:  0.2629629629629629  and last generalization had info loss: 0.27385620915032677\n",
      "We can remove the cluster ID =  7  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 14 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.28758169934640526\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  13  to the current cluster..\n",
      "we are about to output the cluster with ID  8\n",
      "Output of Tuple ID = 9 : 203,134,4,72,117,221,9, with G=[][119-203][18-134][4-196][29-72][117-197][216-221]\n",
      "Output of Tuple ID = 14 : 119,18,196,29,197,216,14, with G=[][119-203][18-134][4-196][29-72][117-197][216-221]\n",
      "param:tau_global updated to:  0.28496732026143784  and last generalization had info loss: 0.3398692810457516\n",
      "We can remove the cluster ID =  8  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 15 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.16601307189542483\n",
      "Tuple with ID: 15 has been added to an existing non-ks-cluster\n",
      "size_non_ks_cluster: 2\n",
      "we are about to output the cluster with ID  9\n",
      "Output of Tuple ID = 10 : 189,144,121,155,228,228,10, with G=[][189-193][136-144][121-150][155-208][72-228][228-232]\n",
      "Output of Tuple ID = 15 : 193,136,150,208,72,232,15, with G=[][189-193][136-144][121-150][155-208][72-228][228-232]\n",
      "param:tau_global updated to:  0.22701525054466232  and last generalization had info loss: 0.16601307189542483\n",
      "Successfully created ks-anonymized cluster ID:  9\n",
      "We can remove the cluster ID =  9  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 16 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.22679738562091503\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  14  to the current cluster..\n",
      "we are about to output the cluster with ID  10\n",
      "Output of Tuple ID = 11 : 166,80,131,227,214,41,11, with G=[][48-166][38-80][131-139][225-227][214-214][41-218]\n",
      "Output of Tuple ID = 16 : 48,38,139,225,214,218,16, with G=[][48-166][38-80][131-139][225-227][214-214][41-218]\n",
      "param:tau_global updated to:  0.22696078431372546  and last generalization had info loss: 0.22679738562091503\n",
      "Successfully created ks-anonymized cluster ID:  10\n",
      "We can remove the cluster ID =  10  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 17 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.43464052287581695\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  15  to the current cluster..\n",
      "we are about to output the cluster with ID  11\n",
      "Output of Tuple ID = 12 : 0,234,230,81,34,219,12, with G=[][0-53][7-234][68-230][60-81][34-81][64-219]\n",
      "Output of Tuple ID = 17 : 53,7,68,60,81,64,17, with G=[][0-53][7-234][68-230][60-81][34-81][64-219]\n",
      "param:tau_global updated to:  0.26849673202614377  and last generalization had info loss: 0.43464052287581695\n",
      "We can remove the cluster ID =  11  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 18 ) +++++++++++++++\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 19 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.4640522875816993\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 20 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.3287581699346405\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 21 ) +++++++++++++++\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated min enlargement for tuple: 0.330718954248366\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 22 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.28692810457516343\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 23 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.2437908496732026\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  21  to the current cluster..\n",
      "we are about to output the cluster with ID  16\n",
      "Output of Tuple ID = 18 : 0,9,35,23,22,35,18, with G=[][0-78][9-229][35-164][23-160][22-31][35-184]\n",
      "Output of Tuple ID = 23 : 78,229,164,160,31,184,23, with G=[][0-78][9-229][35-164][23-160][22-31][35-184]\n",
      "param:tau_global updated to:  0.27594771241830063  and last generalization had info loss: 0.47189542483660135\n",
      "We can remove the cluster ID =  16  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 24 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.28758169934640526\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  22  to the current cluster..\n",
      "we are about to output the cluster with ID  17\n",
      "Output of Tuple ID = 19 : 230,58,142,20,211,167,19, with G=[][23-230][58-247][56-142][20-37][117-211][119-167]\n",
      "Output of Tuple ID = 24 : 23,247,56,37,117,119,24, with G=[][23-230][58-247][56-142][20-37][117-211][119-167]\n",
      "param:tau_global updated to:  0.265359477124183  and last generalization had info loss: 0.4189542483660131\n",
      "We can remove the cluster ID =  17  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 25 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.25947712418300656\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  23  to the current cluster..\n",
      "we are about to output the cluster with ID  18\n",
      "Output of Tuple ID = 20 : 10,64,66,104,165,238,20, with G=[][10-92][64-97][66-84][104-197][165-222][124-238]\n",
      "Output of Tuple ID = 25 : 92,97,84,197,222,124,25, with G=[][10-92][64-97][66-84][104-197][165-222][124-238]\n",
      "param:tau_global updated to:  0.2334640522875817  and last generalization had info loss: 0.25947712418300656\n",
      "We can remove the cluster ID =  18  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 26 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.2718954248366013\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  24  to the current cluster..\n",
      "we are about to output the cluster with ID  19\n",
      "Output of Tuple ID = 21 : 117,180,214,41,95,236,21, with G=[][83-117][131-180][147-214][41-67][95-198][99-236]\n",
      "Output of Tuple ID = 26 : 83,131,147,67,198,99,26, with G=[][83-117][131-180][147-214][41-67][95-198][99-236]\n",
      "param:tau_global updated to:  0.23594771241830065  and last generalization had info loss: 0.2718954248366013\n",
      "We can remove the cluster ID =  19  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 27 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.3470588235294118\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  25  to the current cluster..\n",
      "we are about to output the cluster with ID  20\n",
      "Output of Tuple ID = 22 : 190,55,87,118,129,6,22, with G=[][158-190][17-55][87-231][118-236][26-129][6-102]\n",
      "Output of Tuple ID = 27 : 158,17,231,236,26,102,27, with G=[][158-190][17-55][87-231][118-236][26-129][6-102]\n",
      "param:tau_global updated to:  0.25098039215686274  and last generalization had info loss: 0.3470588235294118\n",
      "We can remove the cluster ID =  20  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 28 ) +++++++++++++++\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 29 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.42941176470588244\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 30 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.4071895424836602\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 31 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.22810457516339866\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 32 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.23464052287581696\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 33 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.2679738562091503\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  31  to the current cluster..\n",
      "we are about to output the cluster with ID  26\n",
      "Output of Tuple ID = 28 : 205,225,39,75,248,77,28, with G=[][65-205][211-225][39-188][68-75][149-248][77-195]\n",
      "Output of Tuple ID = 33 : 65,211,188,68,149,195,33, with G=[][65-205][211-225][39-188][68-75][149-248][77-195]\n",
      "param:tau_global updated to:  0.2504575163398693  and last generalization had info loss: 0.3444444444444445\n",
      "We can remove the cluster ID =  26  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 34 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.2575163398692811\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  32  to the current cluster..\n",
      "we are about to output the cluster with ID  27\n",
      "Output of Tuple ID = 29 : 111,6,187,73,103,28,29, with G=[][58-111][6-28][138-187][73-195][103-237][14-28]\n",
      "Output of Tuple ID = 34 : 58,28,138,195,237,14,34, with G=[][58-111][6-28][138-187][73-195][103-237][14-28]\n",
      "param:tau_global updated to:  0.2330718954248366  and last generalization had info loss: 0.2575163398692811\n",
      "We can remove the cluster ID =  27  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 35 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.292156862745098\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  33  to the current cluster..\n",
      "we are about to output the cluster with ID  28\n",
      "Output of Tuple ID = 30 : 42,135,208,253,28,177,30, with G=[][42-174][6-135][157-208][102-253][28-234][177-234]\n",
      "Output of Tuple ID = 35 : 174,6,157,102,234,234,35, with G=[][42-174][6-135][157-208][102-253][28-234][177-234]\n",
      "param:tau_global updated to:  0.27647058823529413  and last generalization had info loss: 0.47450980392156855\n",
      "We can remove the cluster ID =  28  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 36 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.25882352941176473\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  34  to the current cluster..\n",
      "we are about to output the cluster with ID  29\n",
      "Output of Tuple ID = 31 : 15,122,83,203,156,171,31, with G=[][15-223][119-122][71-83][192-203][102-156][63-171]\n",
      "Output of Tuple ID = 36 : 223,119,71,192,102,63,36, with G=[][15-223][119-122][71-83][192-203][102-156][63-171]\n",
      "param:tau_global updated to:  0.23333333333333334  and last generalization had info loss: 0.25882352941176473\n",
      "We can remove the cluster ID =  29  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 37 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.25882352941176473\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  35  to the current cluster..\n",
      "we are about to output the cluster with ID  30\n",
      "Output of Tuple ID = 32 : 254,132,7,94,195,190,32, with G=[][90-254][132-249][7-44][83-94][194-195][124-190]\n",
      "Output of Tuple ID = 37 : 90,249,44,83,194,124,37, with G=[][90-254][132-249][7-44][83-94][194-195][124-190]\n",
      "param:tau_global updated to:  0.23333333333333334  and last generalization had info loss: 0.25882352941176473\n",
      "We can remove the cluster ID =  30  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 38 ) +++++++++++++++\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 39 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.2294117647058824\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 40 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.3470588235294117\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 41 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.37450980392156863\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 42 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.24901960784313726\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 43 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.23137254901960788\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  41  to the current cluster..\n",
      "we are about to output the cluster with ID  36\n",
      "Output of Tuple ID = 38 : 25,49,76,220,197,18,38, with G=[][25-189][49-81][71-76][91-220][66-197][18-45]\n",
      "Output of Tuple ID = 43 : 189,81,71,91,66,45,43, with G=[][25-189][49-81][71-76][91-220][66-197][18-45]\n",
      "param:tau_global updated to:  0.24535947712418302  and last generalization had info loss: 0.3189542483660131\n",
      "We can remove the cluster ID =  36  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 44 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.22745098039215686\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  42  to the current cluster..\n",
      "we are about to output the cluster with ID  37\n",
      "Output of Tuple ID = 39 : 21,222,35,124,169,27,39, with G=[][21-207][63-222][35-59][80-124][59-169][27-249]\n",
      "Output of Tuple ID = 44 : 207,63,59,80,59,249,44, with G=[][21-207][63-222][35-59][80-124][59-169][27-249]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param:tau_global updated to:  0.27895424836601307  and last generalization had info loss: 0.48692810457516345\n",
      "We can remove the cluster ID =  37  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 45 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.1843137254901961\n",
      "Tuple with ID: 45 has been added to an existing non-ks-cluster\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  40  to the current cluster..\n",
      "we are about to output the cluster with ID  38\n",
      "Output of Tuple ID = 40 : 55,82,185,10,250,114,40, with G=[][55-231][82-173][8-185][10-96][157-250][105-213]\n",
      "Output of Tuple ID = 42 : 216,173,19,96,184,105,42, with G=[][55-231][82-173][8-185][10-96][157-250][105-213]\n",
      "Output of Tuple ID = 45 : 231,103,8,45,157,213,45, with G=[][55-231][82-173][8-185][10-96][157-250][105-213]\n",
      "param:tau_global updated to:  0.27712418300653596  and last generalization had info loss: 0.4777777777777778\n",
      "We can remove the cluster ID =  38  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 46 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.15816993464052287\n",
      "Tuple with ID: 46 has been added to an existing non-ks-cluster\n",
      "size_non_ks_cluster: 2\n",
      "we are about to output the cluster with ID  39\n",
      "Output of Tuple ID = 41 : 129,190,137,79,50,194,41, with G=[][80-129][190-198][51-137][47-79][50-59][136-194]\n",
      "Output of Tuple ID = 46 : 80,198,51,47,59,136,46, with G=[][80-129][190-198][51-137][47-79][50-59][136-194]\n",
      "param:tau_global updated to:  0.21320261437908497  and last generalization had info loss: 0.15816993464052287\n",
      "Successfully created ks-anonymized cluster ID:  39\n",
      "We can remove the cluster ID =  39  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 47 ) +++++++++++++++\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 48 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.5261437908496732\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 49 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.3032679738562091\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 50 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.27777777777777773\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 51 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.16339869281045752\n",
      "Tuple with ID: 51 has been added to an existing non-ks-cluster\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 52 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.09084967320261439\n",
      "Tuple with ID: 52 has been added to an existing non-ks-cluster\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  46  to the current cluster..\n",
      "we are about to output the cluster with ID  43\n",
      "Output of Tuple ID = 47 : 55,38,250,31,76,58,47, with G=[][55-252][38-57][33-250][31-149][76-208][23-58]\n",
      "Output of Tuple ID = 50 : 252,57,33,149,208,23,50, with G=[][55-252][38-57][33-250][31-149][76-208][23-58]\n",
      "param:tau_global updated to:  0.24601307189542482  and last generalization had info loss: 0.46928104575163393\n",
      "We can remove the cluster ID =  43  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 53 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.23921568627450981\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  47  to the current cluster..\n",
      "we are about to output the cluster with ID  44\n",
      "Output of Tuple ID = 48 : 162,141,77,233,242,112,48, with G=[][154-162][50-141][77-92][56-233][206-242][3-112]\n",
      "Output of Tuple ID = 53 : 154,50,92,56,206,3,53, with G=[][154-162][50-141][77-92][56-233][206-242][3-112]\n",
      "param:tau_global updated to:  0.2091503267973856  and last generalization had info loss: 0.2849673202614379\n",
      "We can remove the cluster ID =  44  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 54 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.1326797385620915\n",
      "Tuple with ID: 54 has been added to an existing non-ks-cluster\n",
      "size_non_ks_cluster: 4\n",
      "CASTLE - SPLIT requested..\n",
      "Tuple with ID: 49 has been added to an existing non-ks-cluster\n",
      "Tuple with ID: 54 has been added to an existing non-ks-cluster\n",
      "Splitting completed. We have  2 new clusters after the split operation.\n",
      "we are about to output the cluster with ID  49\n",
      "Output of Tuple ID = 51 : 68,44,67,142,45,65,51, with G=[][68-86][44-68][67-126][142-248][20-45][65-83]\n",
      "Output of Tuple ID = 49 : 86,68,126,248,20,83,49, with G=[][68-86][44-68][67-126][142-248][20-45][65-83]\n",
      "param:tau_global updated to:  0.18483660130718954  and last generalization had info loss: 0.16339869281045752\n",
      "Successfully created ks-anonymized cluster ID:  49\n",
      "We can remove the cluster ID =  49  from the non-ks-cluster set.\n",
      "we are about to output the cluster with ID  50\n",
      "Output of Tuple ID = 52 : 97,90,127,219,15,183,52, with G=[][60-97][90-218][10-127][219-247][5-15][86-183]\n",
      "Output of Tuple ID = 54 : 60,218,10,247,5,86,54, with G=[][60-97][90-218][10-127][219-247][5-15][86-183]\n",
      "param:tau_global updated to:  0.19738562091503267  and last generalization had info loss: 0.27254901960784317\n",
      "We can remove the cluster ID =  50  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 55 ) +++++++++++++++\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 56 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.3418300653594771\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 57 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.23137254901960783\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 58 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.24052287581699347\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 59 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.2627450980392157\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 60 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.1980392156862745\n",
      "Tuple with ID: 60 has been added to an existing non-ks-cluster\n",
      "size_non_ks_cluster: 2\n",
      "we are about to output the cluster with ID  50\n",
      "Output of Tuple ID = 55 : 237,108,129,213,180,159,55, with G=[][234-237][44-108][129-146][152-213][50-180][131-159]\n",
      "Output of Tuple ID = 60 : 234,44,146,152,50,131,60, with G=[][234-237][44-108][129-146][152-213][50-180][131-159]\n",
      "param:tau_global updated to:  0.18248366013071893  and last generalization had info loss: 0.1980392156862745\n",
      "We can remove the cluster ID =  50  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 61 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.2549019607843137\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  55  to the current cluster..\n",
      "we are about to output the cluster with ID  51\n",
      "Output of Tuple ID = 56 : 150,45,248,37,230,131,56, with G=[][150-239][45-179][165-248][37-215][24-230][131-132]\n",
      "Output of Tuple ID = 61 : 239,179,165,215,24,132,61, with G=[][150-239][45-179][165-248][37-215][24-230][131-132]\n",
      "param:tau_global updated to:  0.233202614379085  and last generalization had info loss: 0.4516339869281046\n",
      "We can remove the cluster ID =  51  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 62 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.29411764705882354\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  56  to the current cluster..\n",
      "we are about to output the cluster with ID  52\n",
      "Output of Tuple ID = 57 : 37,195,166,219,168,171,57, with G=[][37-106][32-195][166-170][15-219][168-196][93-171]\n",
      "Output of Tuple ID = 62 : 106,32,170,15,196,93,62, with G=[][37-106][32-195][166-170][15-219][168-196][93-171]\n",
      "param:tau_global updated to:  0.2142483660130719  and last generalization had info loss: 0.3568627450980392\n",
      "We can remove the cluster ID =  52  from the non-ks-cluster set.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 63 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.22483660130718955\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  57  to the current cluster..\n",
      "we are about to output the cluster with ID  53\n",
      "Output of Tuple ID = 58 : 180,114,243,153,114,94,58, with G=[][180-223][87-114][41-243][128-153][114-129][94-126]\n",
      "Output of Tuple ID = 63 : 223,87,41,128,129,126,63, with G=[][180-223][87-114][41-243][128-153][114-129][94-126]\n",
      "param:tau_global updated to:  0.18784313725490195  and last generalization had info loss: 0.22483660130718955\n",
      "We can remove the cluster ID =  53  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 64 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.32483660130718955\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  58  to the current cluster..\n",
      "we are about to output the cluster with ID  54\n",
      "Output of Tuple ID = 59 : 252,81,26,241,31,239,59, with G=[][87-252][81-101][15-26][8-241][31-84][224-239]\n",
      "Output of Tuple ID = 64 : 87,101,15,8,84,224,64, with G=[][87-252][81-101][15-26][8-241][31-84][224-239]\n",
      "param:tau_global updated to:  0.20784313725490197  and last generalization had info loss: 0.32483660130718955\n",
      "We can remove the cluster ID =  54  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 65 ) +++++++++++++++\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 66 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.4470588235294118\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 67 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.2222222222222222\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 68 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.3111111111111111\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 69 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.29411764705882354\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 70 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.1496732026143791\n",
      "Tuple with ID: 70 has been added to an existing non-ks-cluster\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  63  to the current cluster..\n",
      "we are about to output the cluster with ID  59\n",
      "Output of Tuple ID = 65 : 16,23,115,185,95,97,65, with G=[][16-241][23-175][115-170][138-185][95-195][40-97]\n",
      "Output of Tuple ID = 69 : 241,175,170,138,195,40,69, with G=[][16-241][23-175][115-170][138-185][95-195][40-97]\n",
      "param:tau_global updated to:  0.22601307189542483  and last generalization had info loss: 0.415686274509804\n",
      "We can remove the cluster ID =  59  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 71 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.2699346405228758\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  64  to the current cluster..\n",
      "we are about to output the cluster with ID  60\n",
      "Output of Tuple ID = 66 : 153,119,209,89,239,214,66, with G=[][148-153][119-221][209-219][89-206][144-239][31-214]\n",
      "Output of Tuple ID = 71 : 148,221,219,206,144,31,71, with G=[][148-153][119-221][209-219][89-206][144-239][31-214]\n",
      "param:tau_global updated to:  0.20980392156862746  and last generalization had info loss: 0.33464052287581697\n",
      "We can remove the cluster ID =  60  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 72 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.15359477124183005\n",
      "Tuple with ID: 72 has been added to an existing non-ks-cluster\n",
      "size_non_ks_cluster: 2\n",
      "we are about to output the cluster with ID  61\n",
      "Output of Tuple ID = 67 : 162,114,84,183,169,251,67, with G=[][81-162][69-114][84-144][183-211][155-169][251-252]\n",
      "Output of Tuple ID = 70 : 81,69,144,211,155,252,70, with G=[][81-162][69-114][84-144][183-211][155-169][251-252]\n",
      "param:tau_global updated to:  0.17281045751633986  and last generalization had info loss: 0.1496732026143791\n",
      "Successfully created ks-anonymized cluster ID:  61\n",
      "We can remove the cluster ID =  61  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 73 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.3261437908496732\n",
      "size_non_ks_cluster: 2\n",
      "we are about to output the cluster with ID  62\n",
      "Output of Tuple ID = 68 : 124,4,5,101,247,94,68, with G=[][124-213][4-48][5-85][101-106][236-247][88-94]\n",
      "Output of Tuple ID = 72 : 213,48,85,106,236,88,72, with G=[][124-213][4-48][5-85][101-106][236-247][88-94]\n",
      "param:tau_global updated to:  0.1703267973856209  and last generalization had info loss: 0.15359477124183005\n",
      "Successfully created ks-anonymized cluster ID:  62\n",
      "We can remove the cluster ID =  62  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 74 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.20522875816993466\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 75 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.39607843137254894\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 76 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.3601307189542484\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 77 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.22549019607843135\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 78 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.21241830065359477\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  70  to the current cluster..\n",
      "we are about to output the cluster with ID  65\n",
      "Output of Tuple ID = 73 : 129,223,253,48,170,51,73, with G=[][129-151][207-223][44-253][48-95][106-170][51-152]\n",
      "Output of Tuple ID = 78 : 151,207,44,95,106,152,78, with G=[][129-151][207-223][44-253][48-95][106-170][51-152]\n",
      "param:tau_global updated to:  0.1849673202614379  and last generalization had info loss: 0.3\n",
      "We can remove the cluster ID =  65  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 79 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.3209150326797386\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  71  to the current cluster..\n",
      "we are about to output the cluster with ID  66\n",
      "Output of Tuple ID = 74 : 90,60,211,37,219,61,74, with G=[][90-230][60-78][84-211][37-48][28-219][61-181]\n",
      "Output of Tuple ID = 79 : 230,78,84,48,28,181,79, with G=[][90-230][60-78][84-211][37-48][28-219][61-181]\n",
      "param:tau_global updated to:  0.20431372549019605  and last generalization had info loss: 0.39673202614379083\n",
      "We can remove the cluster ID =  66  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 80 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.27385620915032677\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  72  to the current cluster..\n",
      "we are about to output the cluster with ID  67\n",
      "Output of Tuple ID = 75 : 25,118,0,95,134,190,75, with G=[][25-90][118-179][0-234][95-156][32-134][123-190]\n",
      "Output of Tuple ID = 80 : 90,179,234,156,32,123,80, with G=[][25-90][118-179][0-234][95-156][32-134][123-190]\n",
      "param:tau_global updated to:  0.20209150326797384  and last generalization had info loss: 0.3856209150326797\n",
      "We can remove the cluster ID =  67  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 81 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.3032679738562091\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  73  to the current cluster..\n",
      "we are about to output the cluster with ID  68\n",
      "Output of Tuple ID = 76 : 238,191,197,216,125,192,76, with G=[][135-238][178-191][160-197][21-216][125-231][148-192]\n",
      "Output of Tuple ID = 81 : 135,178,160,21,231,148,81, with G=[][135-238][178-191][160-197][21-216][125-231][148-192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param:tau_global updated to:  0.19006535947712416  and last generalization had info loss: 0.3254901960784314\n",
      "We can remove the cluster ID =  68  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 82 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.22287581699346407\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  74  to the current cluster..\n",
      "we are about to output the cluster with ID  69\n",
      "Output of Tuple ID = 77 : 11,36,178,114,180,184,77, with G=[][11-71][36-100][178-224][31-114][180-211][127-184]\n",
      "Output of Tuple ID = 82 : 71,100,224,31,211,127,82, with G=[][11-71][36-100][178-224][31-114][180-211][127-184]\n",
      "param:tau_global updated to:  0.16954248366013072  and last generalization had info loss: 0.22287581699346407\n",
      "We can remove the cluster ID =  69  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 83 ) +++++++++++++++\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 84 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.369281045751634\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 85 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.22549019607843138\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 86 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.21633986928104576\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 87 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.3111111111111111\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 88 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.20261437908496735\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  80  to the current cluster..\n",
      "we are about to output the cluster with ID  75\n",
      "Output of Tuple ID = 83 : 148,87,223,222,253,163,83, with G=[][110-148][87-130][92-223][222-235][197-253][134-163]\n",
      "Output of Tuple ID = 88 : 110,130,92,235,197,134,88, with G=[][110-148][87-130][92-223][222-235][197-253][134-163]\n",
      "param:tau_global updated to:  0.16549019607843135  and last generalization had info loss: 0.20261437908496735\n",
      "We can remove the cluster ID =  75  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 89 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.33137254901960783\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  81  to the current cluster..\n",
      "we are about to output the cluster with ID  76\n",
      "Output of Tuple ID = 84 : 62,74,34,100,159,224,84, with G=[][62-236][23-74][34-163][98-100][130-159][102-224]\n",
      "Output of Tuple ID = 89 : 236,23,163,98,130,102,89, with G=[][62-236][23-74][34-163][98-100][130-159][102-224]\n",
      "param:tau_global updated to:  0.19124183006535947  and last generalization had info loss: 0.33137254901960783\n",
      "We can remove the cluster ID =  76  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 90 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.28496732026143795\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  82  to the current cluster..\n",
      "we are about to output the cluster with ID  77\n",
      "Output of Tuple ID = 85 : 21,176,17,155,101,152,85, with G=[][21-235][85-176][17-255][104-155][101-200][152-168]\n",
      "Output of Tuple ID = 90 : 235,85,255,104,200,168,90, with G=[][21-235][85-176][17-255][104-155][101-200][152-168]\n",
      "param:tau_global updated to:  0.2176470588235294  and last generalization had info loss: 0.4633986928104575\n",
      "We can remove the cluster ID =  77  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 91 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.15163398692810456\n",
      "Tuple with ID: 91 has been added to an existing non-ks-cluster\n",
      "size_non_ks_cluster: 2\n",
      "we are about to output the cluster with ID  78\n",
      "Output of Tuple ID = 86 : 0,158,94,4,102,215,86, with G=[][0-2][158-175][94-142][4-21][102-210][175-215]\n",
      "Output of Tuple ID = 91 : 2,175,142,21,210,175,91, with G=[][0-2][158-175][94-142][4-21][102-210][175-215]\n",
      "param:tau_global updated to:  0.15529411764705883  and last generalization had info loss: 0.15163398692810456\n",
      "Successfully created ks-anonymized cluster ID:  78\n",
      "We can remove the cluster ID =  78  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 92 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.29869281045751633\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  83  to the current cluster..\n",
      "we are about to output the cluster with ID  79\n",
      "Output of Tuple ID = 87 : 229,240,100,80,188,252,87, with G=[][229-239][121-240][100-216][43-80][185-188][80-252]\n",
      "Output of Tuple ID = 92 : 239,121,216,43,185,80,92, with G=[][229-239][121-240][100-216][43-80][185-188][80-252]\n",
      "param:tau_global updated to:  0.1833986928104575  and last generalization had info loss: 0.29869281045751633\n",
      "We can remove the cluster ID =  79  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 93 ) +++++++++++++++\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 94 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.3405228758169934\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 95 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.12483660130718954\n",
      "Tuple with ID: 95 has been added to an existing non-ks-cluster\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 96 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.16666666666666666\n",
      "Tuple with ID: 96 has been added to an existing non-ks-cluster\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 97 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.14640522875816994\n",
      "Tuple with ID: 97 has been added to an existing non-ks-cluster\n",
      "..this tuple has already been outputted before\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 98 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.20915032679738563\n",
      "size_non_ks_cluster: 1\n",
      "..successfully merged cluster ID =  86  to the current cluster..\n",
      "we are about to output the cluster with ID  84\n",
      "Output of Tuple ID = 93 : 93,182,86,226,222,173,93, with G=[][22-93][5-182][86-249][23-226][177-222][58-173]\n",
      "Output of Tuple ID = 98 : 22,5,249,23,177,58,98, with G=[][22-93][5-182][86-249][23-226][177-222][58-173]\n",
      "param:tau_global updated to:  0.22483660130718955  and last generalization had info loss: 0.5058823529411764\n",
      "We can remove the cluster ID =  84  from the non-ks-cluster set.\n",
      "+++++++++++ We give the CASTLE algorithm the next tuple ( 99 ) +++++++++++++++\n",
      "Calculated min enlargement for tuple: 0.21830065359477124\n",
      "size_non_ks_cluster: 4\n",
      "CASTLE - SPLIT requested..\n",
      "Tuple with ID: 94 has been added to an existing non-ks-cluster\n",
      "Tuple with ID: 96 has been added to an existing non-ks-cluster\n",
      "Splitting completed. We have  2 new clusters after the split operation.\n",
      "we are about to output the cluster with ID  89\n",
      "Output of Tuple ID = 95 : 219,156,213,227,73,18,95, with G=[][136-219][156-156][213-230][197-227][73-116][0-18]\n",
      "Output of Tuple ID = 94 : 136,156,230,197,116,0,94, with G=[][136-219][156-156][213-230][197-227][73-116][0-18]\n",
      "param:tau_global updated to:  0.14862745098039215  and last generalization had info loss: 0.12483660130718954\n",
      "Successfully created ks-anonymized cluster ID:  89\n",
      "We can remove the cluster ID =  89  from the non-ks-cluster set.\n",
      "we are about to output the cluster with ID  90\n",
      "Output of Tuple ID = 97 : 137,206,214,36,82,205,97, with G=[][137-175][150-206][185-214][8-36][82-135][31-205]\n",
      "Output of Tuple ID = 96 : 175,150,185,8,135,31,96, with G=[][137-175][150-206][185-214][8-36][82-135][31-205]\n",
      "param:tau_global updated to:  0.16535947712418303  and last generalization had info loss: 0.24705882352941178\n",
      "We can remove the cluster ID =  90  from the non-ks-cluster set.\n",
      "--> --> --> --> --> --> --> CASTLE rounds are over --> --> --> --> --> --> -->\n",
      "--> Output the non-ks-clusters in memory: \n",
      " G=[] [68-68][46-46][107-107][41-41][204-204][220-220]tupleIDs[[99]]clusterID =[87]\n",
      "\n",
      "--> Output the ks-clusters reusable: \n",
      " G=[] [102-110][18-179][108-254][33-104][136-147][16-185]tupleIDs[[0, 4]]clusterID =[0]\n",
      "G=[] [112-208][68-150][26-151][166-217][83-195][215-216]tupleIDs[[5, 1]]clusterID =[5]\n",
      "G=[] [224-240][102-137][236-254][11-35][45-115][36-194]tupleIDs[[2, 7]]clusterID =[2]\n",
      "G=[] [189-193][136-144][121-150][155-208][72-228][228-232]tupleIDs[[10, 15]]clusterID =[9]\n",
      "G=[] [48-166][38-80][131-139][225-227][214-214][41-218]tupleIDs[[11, 16]]clusterID =[10]\n",
      "G=[] [80-129][190-198][51-137][47-79][50-59][136-194]tupleIDs[[41, 46]]clusterID =[39]\n",
      "G=[] [68-86][44-68][67-126][142-248][20-45][65-83]tupleIDs[[51, 49]]clusterID =[49]\n",
      "G=[] [81-162][69-114][84-144][183-211][155-169][251-252]tupleIDs[[67, 70]]clusterID =[61]\n",
      "G=[] [124-213][4-48][5-85][101-106][236-247][88-94]tupleIDs[[68, 72]]clusterID =[62]\n",
      "G=[] [0-2][158-175][94-142][4-21][102-210][175-215]tupleIDs[[86, 91]]clusterID =[78]\n",
      "G=[] [136-219][156-156][213-230][197-227][73-116][0-18]tupleIDs[[95, 94]]clusterID =[89]\n",
      "\n",
      "Number of non-ks-clusters (not yet outputted): 1\n",
      "Number of re-usuable ks-clusters outputted: 11\n"
     ]
    }
   ],
   "source": [
    "testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
